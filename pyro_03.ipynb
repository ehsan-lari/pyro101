{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP37CDbl4F5sVeWCAyTi5Cd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehsan-lari/pyro101/blob/main/pyro_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Linear Regression"
      ],
      "metadata": {
        "id": "4kSlT-T7bAyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import matplotlib.colors as mcolors\n",
        "from scipy.stats import multivariate_normal, norm\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "EGYKBqBHdZDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = \"https://github.com/pyro-ppl/brmp/raw/master/brmp/examples/rugged_data.csv\"\n",
        "data = pd.read_csv(DATA_URL, encoding=\"ISO-8859-1\")\n",
        "df = data[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]\n",
        "df = df.sample(frac=1)\n",
        "df = df[np.isfinite(df.rgdppc_2000)]\n",
        "df[\"rgdppc_2000\"] = np.log(df[\"rgdppc_2000\"])\n",
        "df = df[[\"cont_africa\", \"rugged\", \"rgdppc_2000\"]]"
      ],
      "metadata": {
        "id": "JqFlxlFUdcIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(df)\n",
        "x_data = {'non-african': data[data[:, 0] == 0, 1].reshape(-1,1), 'african': data[data[:, 0] == 1, 1].reshape(-1,1)}\n",
        "y_data = {'non-african': data[data[:, 0] == 0, -1], 'african': data[data[:, 0] == 1, -1]}\n",
        "\n",
        "print(x_data['african'].shape)\n",
        "print(x_data['non-african'].shape)"
      ],
      "metadata": {
        "id": "fZ9WYkZKePxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Regression model"
      ],
      "metadata": {
        "id": "LcxmsEXmodbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RegressionModel():\n",
        "    def __init__(self):\n",
        "        self.w = torch.nn.Parameter(torch.zeros(1, 1))\n",
        "        self.b = torch.nn.Parameter(torch.zeros(1, 1))\n",
        "\n",
        "    def params(self):\n",
        "        return {\"b\": self.b, \"w\": self.w}\n",
        "\n",
        "    def predict(self, x_data):\n",
        "        return (self.b + torch.mm(self.w, torch.t(x_data))).squeeze(0)"
      ],
      "metadata": {
        "id": "PMypp95_p4n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def least_squares_solution(x_data, y_data, verbose=True):\n",
        "  regression_model = RegressionModel()\n",
        "  loss_fn = nn.MSELoss(reduction='sum')\n",
        "  optim = torch.optim.Adam(regression_model.params().values(), lr=1e-1)\n",
        "  NUM_ITERATIONS = 1000\n",
        "\n",
        "  param = {}\n",
        "\n",
        "  for cont in x_data.keys():\n",
        "    param[cont] = {}\n",
        "    if verbose:\n",
        "      print(f\"Learning model for {cont} nations\")\n",
        "    for iter in range(NUM_ITERATIONS):\n",
        "      y_pred = regression_model.predict(torch.tensor(x_data[cont], dtype=torch.float))\n",
        "      loss = loss_fn(y_pred, torch.tensor(y_data[cont], dtype=torch.float))\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "    param[cont]['w'] = regression_model.params()['w'].item()\n",
        "    param[cont]['b'] = regression_model.params()['b'].item()\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"Learned parameters:\")\n",
        "      for cont in param.keys():\n",
        "        print(f\"{cont}: w = {param[cont]['w']:.4f}, b = {param[cont]['b']:.4f}\")\n",
        "  return param"
      ],
      "metadata": {
        "id": "sy0h4adDoJ5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lr = least_squares_solution(x_data, y_data)"
      ],
      "metadata": {
        "id": "Jhicufuevces"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Bayesian linear regression model"
      ],
      "metadata": {
        "id": "SCVklb1N3iiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Calculate ELBO"
      ],
      "metadata": {
        "id": "N39e-QmnAGJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ELBO(x_data, y_data, gamma_w, gamma_b, theta, q_w_mean, q_w_prec, q_b_mean, q_b_prec):\n",
        "\n",
        "  M = x_data.shape[1]\n",
        "\n",
        "  E_log_p = -.5 * M * np.log( (2 * np.pi)) + .5 * M * np.log( gamma_w ) \\\n",
        "            -.5 * gamma_w * np.sum( np.diag(np.linalg.inv(q_w_prec)) + (q_w_mean**2).flatten() )\n",
        "\n",
        "  E_log_p += -.5 * np.log( (2 * np.pi)) + .5 * np.log(gamma_b) -.5 * gamma_b * ( 1/q_b_prec + q_b_mean**2)\n",
        "\n",
        "  E_w_w = np.linalg.inv(q_w_prec) + q_w_mean @ q_w_mean.T\n",
        "  E_b_b = 1/q_b_prec + q_b_mean**2\n",
        "\n",
        "  for i in range(x_data.shape[0]):\n",
        "    E_x_ww_x = np.matmul(np.transpose(x_data[i, :]), E_w_w @ x_data[i, :])\n",
        "    E_log_p += -.5 * np.log((2 * np.pi)) + .5 * np.log(theta) \\\n",
        "               -.5 * theta * (y_data[i]**2 + E_x_ww_x + E_b_b\n",
        "                              + 2 * q_b_mean * q_w_mean.T @ x_data[i, :]\n",
        "                              - 2 * y_data[i] * q_w_mean.T @ x_data[i, :]\n",
        "                              - 2 * y_data[i] * q_b_mean)\n",
        "\n",
        "  ent = .5 * np.log( (np.pi) * np.exp(1) / q_b_prec )\n",
        "  ent += .5 * np.log(np.linalg.det( 2 * np.pi * np.exp(1) * np.linalg.inv(q_w_prec) ) )\n",
        "\n",
        "  return E_log_p - ent"
      ],
      "metadata": {
        "id": "0GlxJxsc3qkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Updating equations"
      ],
      "metadata": {
        "id": "Aa7Kr3AUGMnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_w(x_data, y_data, gamma_w, theta, q_w_mean, q_w_prec, q_b_mean, comp):\n",
        "  M = x_data.shape[1]\n",
        "  tau = gamma_w\n",
        "  mu = 0.0\n",
        "\n",
        "  for i in range(x_data.shape[0]):\n",
        "    tau += theta * x_data[i, comp]**2\n",
        "    mu += (y_data[i] * q_b_mean - (np.sum(x_data[i, :] @ q_w_mean ) - x_data[i, comp] * q_w_mean[comp] ) ) * x_data[i, comp]\n",
        "\n",
        "  mu = theta * 1/tau * mu\n",
        "\n",
        "  q_w_prec[comp, comp] = tau\n",
        "  q_w_mean[comp] = mu.item()\n",
        "\n",
        "  return q_w_mean, q_w_prec\n",
        "\n",
        "def update_b(x_data, y_data, gamma_b, theta, q_w_mean):\n",
        "  tau = (gamma_b + theta * x_data.shape[0])\n",
        "  mu = 0.0\n",
        "\n",
        "  for i in range(x_data.shape[0]):\n",
        "    mu += (y_data[i] - q_w_mean.T @ x_data[i, :])\n",
        "\n",
        "  mu = theta * 1/tau * mu\n",
        "\n",
        "  return tau, mu"
      ],
      "metadata": {
        "id": "drOG3ueNBxDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_solution(x_data, y_data, gamma_w: float = 1, gamma_b: float = 1, theta: float = 1, verbose=True):\n",
        "    \"\"\"\n",
        "    Perform variational inference using the coordinate ascent updating rules. The two models (for african and\n",
        "    non-african nations are learned independently.\n",
        "    :param x_data: dictionary with data for the predictor variable\n",
        "    :param y_data: dictionary with data for the response variable\n",
        "    :param gamma_w: precision for the weight/slope term\n",
        "    :param gamma_b: precision for the bias term\n",
        "    :param theta: prior precision for y\n",
        "    :param verbose: Do we want to display information from the updating process?\n",
        "    :return: The model (i.e., mean and covariance) in a dictionary with one element for african and non-african.\n",
        "    \"\"\"\n",
        "    param = {}\n",
        "\n",
        "    if verbose:\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6), sharey=True)\n",
        "        fig.suptitle(\"Evolution of ELBO\", fontsize=16)\n",
        "\n",
        "     # Do the learning for african and non-african nations\n",
        "    for idx, cont in enumerate(x_data):\n",
        "        param[cont] = {}\n",
        "        M = x_data[cont].shape[1]\n",
        "        q_w_mean = np.random.normal(0, 1, (1, 1))\n",
        "        q_w_prec = np.array([[1]])\n",
        "        q_b_mean = np.random.normal(0, 1)\n",
        "        q_b_prec = 1\n",
        "        elbos = []\n",
        "\n",
        "        # Calculate ELBO\n",
        "        this_lb = calculate_ELBO(x_data[cont], y_data[cont], gamma_w, gamma_b, theta, q_w_mean, q_w_prec, q_b_mean, q_b_prec)\n",
        "        elbos.append(this_lb)\n",
        "        previous_lb = -np.inf\n",
        "        # Start iterating\n",
        "        if verbose:\n",
        "            print(\"\\n\" + 100 * \"=\" + \"\\n   VB iterations:\\n\" + 100 * \"=\")\n",
        "        for iteration in range(100):\n",
        "\n",
        "            # Update the variational distributions\n",
        "            for i in range(M):\n",
        "                q_w_prec, q_w_mean = update_w(x_data[cont], y_data[cont], gamma_w, theta, q_w_mean, q_w_prec, q_b_mean, i)\n",
        "            q_b_prec, q_b_mean = update_b(x_data[cont], y_data[cont], gamma_b, theta, q_w_mean)\n",
        "\n",
        "            this_lb = calculate_ELBO(x_data[cont], y_data[cont], gamma_w, gamma_b, theta, q_w_mean, q_w_prec, q_b_mean, q_b_prec)\n",
        "            elbos.append(this_lb)\n",
        "            if verbose:\n",
        "                print(f\"Iteration {iteration:2d}. ELBO: {this_lb.item():13.7f}\")\n",
        "            if this_lb < previous_lb:\n",
        "                raise ValueError(\"ELBO is decreasing. Something is wrong! Goodbye...\")\n",
        "\n",
        "            if iteration > 0 and np.abs((this_lb - previous_lb) / previous_lb) < 1E-8:\n",
        "                # Very little improvement. We are done.\n",
        "                break\n",
        "\n",
        "            # If we didn't break we need to run again. Update the value for \"previous\"\n",
        "            previous_lb = this_lb\n",
        "        if verbose:\n",
        "            print(\"\\n\" + 100 * \"=\" + \"\\n\")\n",
        "\n",
        "        param[cont]['w'] = np.r_[q_b_mean, q_w_mean.flatten()]\n",
        "        param[cont]['cov'] = np.linalg.inv(np.diag(np.r_[q_b_prec, q_w_prec.flatten()]))\n",
        "\n",
        "        if verbose:\n",
        "            ax[idx].plot(range(len(elbos)), elbos, label='Mean field approximation: ELBO')\n",
        "            ax[idx].set(xlabel=\"Number of iterations\",\n",
        "                        ylabel=\"ELBO\",\n",
        "                        title=f\"{cont} nations\")\n",
        "            ax[idx].legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Inspect learned parameters\n",
        "    if verbose:\n",
        "        print(\"Learned parameters:\")\n",
        "        for cont in param.keys():\n",
        "            print(f\"For {cont} nations\")\n",
        "            for name, value in param[cont].items():\n",
        "                print(f\"{name} = \")\n",
        "                print(f\"{value}\")\n",
        "\n",
        "    return param"
      ],
      "metadata": {
        "id": "eChNaC_9I8H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mf = variational_solution(x_data, y_data, gamma_w=1, gamma_b=1, theta=1)"
      ],
      "metadata": {
        "id": "3cJeBVFWJLby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}